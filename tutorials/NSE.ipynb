{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Nash-Sutcliffe Efficiency (NSE)\n",
    "In this tutorial, we will calculate the Nash-Sutcliffe Efficiency (NSE) coefficient using the function `scores.continuous.nse`.\n",
    "\n",
    "NSE is a widely used metric in hydrology and other fields to evaluate the performance of a model by comparing its predictions to observed data.\n",
    "\n",
    "## Definition\n",
    "\n",
    "The Nash-Sutcliffe Efficiency (NSE) is defined as:\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "\\large{\\text{NSE}} &= 1 - \\large\\frac{\\large\\sum_{i=1}^{n}(f_i - o_i)^2}{\\large\\sum_{i=1}^{n}(o_i - \\bar{o})^2} \\\\ \n",
    "                     &= 1 - \\large\\frac{\\text{MSE}}{\\sigma_{o}^2} \\\\ \n",
    "\\end{align*}\n",
    "$$\n",
    "<br>Where:\n",
    "- $f_i$ is the forecast or predicted value\n",
    "- $o_i$ is the observed value\n",
    "- $\\bar{o}$ is the mean of the observed values\n",
    "- $n$ is the number of data points\n",
    "- $\\sigma_{\\large{o}}^2$ is the un-weighted observation variance\n",
    "- MSE is the mean-squared error, equivilent to the `scores` function: `scores.continuous.mse`\n",
    "\n",
    "\n",
    "Scores also supports the use of `weights`. These can be used to scale both the individual forecast error in the numerator and the deviation from the observation mean in the denominator. This is also known as the weighted-NSE or wNSE (for an application of this, see: [Hundecha and Bárdossy (2004)](https://doi.org/10.1016/j.jhydrol.2004.01.002)).\n<br>",
    "$$\n",
    "\\begin{align*}\n",
    "\\large{\\text{wNSE}} &= 1 - \\large\\frac{\\large\\sum_{i=1}^{n}w_i.(f_i - o_i)^2}{\\large\\sum_{i=1}^{n}w_i.(o_i - \\bar{o})^2} \\\\ \n",
    "                      &= 1 - \\large\\frac{\\text{MWSE}}{\\sigma_{o_w}^2} \\\\ \n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "<br>Where:\n",
    "- $\\vec{w} = (w_1, w_2,..., w_n)$ are the weights for each index $i$\n",
    "- The weights must be non-negative: $\\forall i \\ : \\ 0 \\leq w_i\\ , \\ \\text{and there exists at least one}\\ \\  i \\ : \\ 0 \\lt w_i$  (specifiable using `weights` option)\n",
    "- $\\sigma_{\\large{o_w}}^2$ is the weighted obs variance\n",
    "- $\\small\\text{MWSE}$ is the mean of the weighted square errors - again this is also equivilent to `scores.continuous.mse`, if using the weights argument\n",
    "\n",
    " > **caution:** $\\small\\text{MWSE}$ (scores) should not be confused with $\\small\\text{WMSE}$ (weighted mean square errror):\n",
    " > - $\\small\\text{WMSE}$ is a _\"weighted mean\"_ of _\"unweighted\"_ error terms.<br>\n",
    " > - On the other hand, $\\small\\text{MWSE}$ is a _\"unweighted mean\"_ of _\"weighted\"_ error terms.<br>\n",
    " > - The distinction is subtle, essentially: $\\small\\text{WMSE}$ treats 0 weights as data to *exclude*; additionally it requires that the *weights sum to 1*.\n",
    " > - Whereas $\\small\\text{MWSE}$ (what `scores` does), treats 0 weights as data that is *zero forced* and has no constraints on the upper bound of the *weights* (at the time of writing).\n",
    " > - Incidentally $\\small\\text{MWSE}$ is also what is needed to compute a \"weighted\" NSE ($\\small\\text{wNSE}$).\n",
    "\n",
    "Further, while $i$ above is shown as a integer index from 0 to n, its definition can be abstracted to any _multi-index_ i.e.\n",
    "\n",
    "$\\vec{i} \\in \\{ \\left(\\ i_0,\\ i_1,\\ ...\\ \\right) :\\  0\\leq i_0 \\lt N_0;\\ 0\\leq i_1 \\lt N_1; \\ ...\\ \\}$\n",
    "\n",
    "If one wishes to accumulate the NSE scores over multiple indices, the `reduce_dims` and `preserve_dims` arguments can be used (similar to other scores).\n",
    "\n",
    "## Interpretation\n",
    "\n",
    "A perfect model has an NSE value of 1, while a model performing as poorly as the mean of the observed data has an NSE value of 0 or less.\n",
    "\n",
    "In hydrological modeling, the Nash–Sutcliffe Efficiency (NSE) is essential for assessing model performance. An NSE of 1 indicates perfect prediction, while 0 suggests the model performs as well as predicting the mean of the data. Negative values imply the observed mean is a better predictor. NSE values closer to 1 denote superior predictive ability. In regression analyses, NSE parallels the coefficient of determination (R²), representing model fit on a scale from 0 to 1.\n",
    "\n",
    "> **Note:**\n",
    "> \n",
    "> The image (co-domain) of $R^2 : (x, x_\\text{fit}) \\rightarrow \\text{score}$ does not necessarily need to be constrained to $[0, 1]$. It's just that a linear least squares optimisation makes it impossible for a fit to do worse than the mean.\n",
    ">\n",
    "> Analysis using NSE explicitly doesn't pose such restrictions. Its more akin to the signal to noise ratio in this sense, in fact\n",
    ">\n",
    "> $\\text{SNR} \\Large = \\frac{E[{O^2}]}{E[\\xi_\\text{model}^2]} = \\frac{\\sigma_{o}^2}{\\text{MSE}} = \\frac{1}{1 - NSE}$\n",
    "> \n",
    "> Where, $O$ is the observed process (\"signal\"), and $\\xi_\\text{model}$ is the error of the modelled predictions/forecasts/simulations (\"noise\")\n",
    "\n",
    "## References\n",
    "1. Nash, J. E., & Sutcliffe, J. V. (1970). River flow forecasting through conceptual models part I — A discussion of principles. Journal of Hydrology, 10(3), 282–290. https://doi.org/10.1016/0022-1694(70)90255-6 <br>\n",
    "2. Hundecha, Y., & Bárdossy, A. (2004). Modeling of the effect of land use changes on the runoff generation of a river basin through parameter regionalization of a watershed model. Journal of Hydrology, 292(1–4), 281–295. https://doi.org/10.1016/j.jhydrol.2004.01.002 <br>\n",
    "\n",
    "\n",
    "## Using the `nse` Function\n",
    "\n",
    "Let's start by importing the `nse` function from our module and exploring its usage with different types of input data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scores.continuous import nse\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import pandas as pd\n",
    "\n",
    "np.random.seed(0)  # set the seed to make notebook reproducible"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 1: Xarray DataArray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NSE for Xarray DataArray: <xarray.DataArray 'NSE' ()> Size: 8B\n",
      "array(0.5)\n"
     ]
    }
   ],
   "source": [
    "fcst_xr = xr.DataArray([3, 4, 5, 6, 7])\n",
    "obs_xr = xr.DataArray([2, 3, 4, 5, 6])\n",
    "nse_xr = nse(fcst_xr, obs_xr)\n",
    "print(\"NSE for Xarray DataArray:\", nse_xr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 2: Large Xarray DataArrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NSE for large Xarray DataArrays: <xarray.DataArray 'NSE' ()> Size: 8B\n",
      "array(-0.9995806)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "fcst_large = xr.DataArray(\n",
    "    data=np.random.random_sample((1000, 1000)) * 360,\n",
    "    dims=[\"space\", \"time\"],\n",
    "    coords=[np.arange(0, 1000), np.arange(0, 1000)],\n",
    ")\n",
    "obs_large = xr.DataArray(\n",
    "    data=np.random.random_sample((1000, 1000)) * 360,\n",
    "    dims=[\"space\", \"time\"],\n",
    "    coords=[np.arange(0, 1000), np.arange(0, 1000)],\n",
    ")\n",
    "nse_large = nse(fcst_large, obs_large)\n",
    "print(\"NSE for large Xarray DataArrays:\", nse_large)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 3: Angular and Array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NSE for angular types: <xarray.DataArray 'NSE' ()> Size: 8B\n",
      "array(0.5)\n"
     ]
    }
   ],
   "source": [
    "fcst_xr = xr.DataArray([3, 4, 5, 6, 7])\n",
    "obs_xr = xr.DataArray([2, 3, 4, 5, 6])\n",
    "nse_anular = nse(fcst_xr, obs_xr, is_angular=True)\n",
    "print(\"NSE for angular types:\", nse_anular)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 4: Weight and Array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NSE with weights types: <xarray.DataArray 'NSE' ()> Size: 8B\n",
      "array(0.25)\n"
     ]
    }
   ],
   "source": [
    "fcst_xr = xr.DataArray([3, 4, 5, 6, 7])\n",
    "obs_xr = xr.DataArray([2, 3, 4, 5, 6])\n",
    "weights = xr.DataArray(np.array([1, 2, 3, 2, 1]))\n",
    "nse_weights = nse(fcst_xr, obs_xr, weights=weights)\n",
    "print(\"NSE with weights types:\", nse_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 5: 2D Array: Time and Station"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_synthetic_2d_data():\n",
    "    # Define dimensions\n",
    "    time = pd.date_range(\"2024-01-01\", periods=5, freq=\"D\")\n",
    "    stations = [\"Station1\", \"Station2\", \"Station3\"]\n",
    "\n",
    "    # Use specified forecast and observed values\n",
    "    forecast_data = np.array(\n",
    "        [[3, 4, 5, 6, 7], [3, 4, 5, 6, 7], [3, 4, 5, 6, 7]]\n",
    "    ).T  # Transpose to align with dimensions (time, station)\n",
    "    observed_data = np.array(\n",
    "        [[2, 3, 4, 5, 6], [2, 3, 4, 5, 6], [2, 3, 4, 5, 6]]\n",
    "    ).T  # Transpose to align with dimensions (time, station)\n",
    "\n",
    "    # Create forecast DataArray\n",
    "    forecast_da = xr.DataArray(\n",
    "        forecast_data, coords={\"time\": time, \"station\": stations}, dims=[\"time\", \"station\"], name=\"forecast\"\n",
    "    )\n",
    "\n",
    "    # Create observed DataArray\n",
    "    observed_da = xr.DataArray(\n",
    "        observed_data, coords={\"time\": time, \"station\": stations}, dims=[\"time\", \"station\"], name=\"observed\"\n",
    "    )\n",
    "\n",
    "    return forecast_da, observed_da"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NSE for station: <xarray.DataArray 'NSE' (station: 3)> Size: 24B\n",
      "array([0.5, 0.5, 0.5])\n",
      "Coordinates:\n",
      "  * station  (station) <U8 96B 'Station1' 'Station2' 'Station3'\n"
     ]
    }
   ],
   "source": [
    "# Create synthetic forecast and observed DataArrays\n",
    "fcst_xr, obs_xr = create_synthetic_2d_data()\n",
    "\n",
    "# Calculate the NSE for the test case, reducing over time - giving one value per station\n",
    "nse_value = nse(fcst_xr, obs_xr, reduce_dims=\"time\")\n",
    "print(\"NSE for station:\", nse_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 6: 3D Array: Ensemble, Station and Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_synthetic_3d_data():\n",
    "    # Define dimensions\n",
    "    time = pd.date_range(\"2024-01-01\", periods=5, freq=\"D\")\n",
    "    stations = [\"Station1\", \"Station2\", \"Station3\"]\n",
    "    ensemble = [\"Ensemble1\", \"Ensemble2\", \"Ensemble3\"]\n",
    "\n",
    "    # Use specified forecast and observed values\n",
    "    forecast_data = np.array(\n",
    "        [[3, 4, 5, 6, 7], [3, 4, 5, 6, 7], [3, 4, 5, 6, 7]]\n",
    "    ).T  # Transpose to align with dimensions (time, station)\n",
    "    observed_data = np.array(\n",
    "        [[2, 3, 4, 5, 6], [2, 3, 4, 5, 6], [2, 3, 4, 5, 6]]\n",
    "    ).T  # Transpose to align with dimensions (time, station)\n",
    "\n",
    "    # Repeat data for each ensemble member\n",
    "    forecast_data = np.repeat(forecast_data[np.newaxis, ...], len(ensemble), axis=0)\n",
    "    observed_data = np.repeat(observed_data[np.newaxis, ...], len(ensemble), axis=0)\n",
    "\n",
    "    # Create forecast DataArray\n",
    "    forecast_da = xr.DataArray(\n",
    "        forecast_data,\n",
    "        coords={\"ensemble\": ensemble, \"time\": time, \"station\": stations},\n",
    "        dims=[\"ensemble\", \"time\", \"station\"],\n",
    "        name=\"forecast\",\n",
    "    )\n",
    "\n",
    "    # Create observed DataArray\n",
    "    observed_da = xr.DataArray(\n",
    "        observed_data,\n",
    "        coords={\"ensemble\": ensemble, \"time\": time, \"station\": stations},\n",
    "        dims=[\"ensemble\", \"time\", \"station\"],\n",
    "        name=\"observed\",\n",
    "    )\n",
    "\n",
    "    return forecast_da, observed_da"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NSE for station: <xarray.DataArray 'NSE' (ensemble: 3, time: 5)> Size: 120B\n",
      "array([[-inf, -inf, -inf, -inf, -inf],\n",
      "       [-inf, -inf, -inf, -inf, -inf],\n",
      "       [-inf, -inf, -inf, -inf, -inf]])\n",
      "Coordinates:\n",
      "  * ensemble  (ensemble) <U9 108B 'Ensemble1' 'Ensemble2' 'Ensemble3'\n",
      "  * time      (time) datetime64[ns] 40B 2024-01-01 2024-01-02 ... 2024-01-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<REDACTED>: UserWarning: \n",
      "    NSE: possible divide by zero - at least one element in the reduced obs\n",
      "    variance array is 0.  Any divide by zero entries will be filled in as `np.nan` if the forecast\n",
      "    error is also 0, otherwise it will be `-np.inf`. This is so that any other valid entries are\n",
      "    still computed and returned.  The user should still verify that zero obs variance is expected\n",
      "    for the given input data.\n",
      "    \n",
      "  warnings.warn(NseUtils.WARN_ZERO_OBS_VARIANCE)\n"
     ]
    }
   ],
   "source": [
    "fcst_xr, obs_xr = create_synthetic_3d_data()\n",
    "\n",
    "# Calculate the NSE for the test case, this time over the station, giving one value per time and ensemble\n",
    "nse_value = nse(fcst_xr, obs_xr, reduce_dims=\"station\")\n",
    "print(\"NSE for station:\", nse_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **divide by zero warning:**\n",
    "> We got a divide by zero warning. This is *expected* since for each `(ensemble, time)` the value is the *same*. Recall that the NSE has the observation variance as the denominator. If the obs values are the same this implies that the variance is zero, we'd then have $\\text{NSE} = 1 - \\frac{\\text{fcst\\_error}}{0} = 1 - \\infty = -\\infty$. Usually the data isn't this contrived and we may still want to use the partial results - despite the ocassional divide by zero. To facilitate this, a warning is thrown instead of an error.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><svg style=\"position: absolute; width: 0; height: 0; overflow: hidden\">\n",
       "<defs>\n",
       "<symbol id=\"icon-database\" viewBox=\"0 0 32 32\">\n",
       "<path d=\"M16 0c-8.837 0-16 2.239-16 5v4c0 2.761 7.163 5 16 5s16-2.239 16-5v-4c0-2.761-7.163-5-16-5z\"></path>\n",
       "<path d=\"M16 17c-8.837 0-16-2.239-16-5v6c0 2.761 7.163 5 16 5s16-2.239 16-5v-6c0 2.761-7.163 5-16 5z\"></path>\n",
       "<path d=\"M16 26c-8.837 0-16-2.239-16-5v6c0 2.761 7.163 5 16 5s16-2.239 16-5v-6c0 2.761-7.163 5-16 5z\"></path>\n",
       "</symbol>\n",
       "<symbol id=\"icon-file-text2\" viewBox=\"0 0 32 32\">\n",
       "<path d=\"M28.681 7.159c-0.694-0.947-1.662-2.053-2.724-3.116s-2.169-2.030-3.116-2.724c-1.612-1.182-2.393-1.319-2.841-1.319h-15.5c-1.378 0-2.5 1.121-2.5 2.5v27c0 1.378 1.122 2.5 2.5 2.5h23c1.378 0 2.5-1.122 2.5-2.5v-19.5c0-0.448-0.137-1.23-1.319-2.841zM24.543 5.457c0.959 0.959 1.712 1.825 2.268 2.543h-4.811v-4.811c0.718 0.556 1.584 1.309 2.543 2.268zM28 29.5c0 0.271-0.229 0.5-0.5 0.5h-23c-0.271 0-0.5-0.229-0.5-0.5v-27c0-0.271 0.229-0.5 0.5-0.5 0 0 15.499-0 15.5 0v7c0 0.552 0.448 1 1 1h7v19.5z\"></path>\n",
       "<path d=\"M23 26h-14c-0.552 0-1-0.448-1-1s0.448-1 1-1h14c0.552 0 1 0.448 1 1s-0.448 1-1 1z\"></path>\n",
       "<path d=\"M23 22h-14c-0.552 0-1-0.448-1-1s0.448-1 1-1h14c0.552 0 1 0.448 1 1s-0.448 1-1 1z\"></path>\n",
       "<path d=\"M23 18h-14c-0.552 0-1-0.448-1-1s0.448-1 1-1h14c0.552 0 1 0.448 1 1s-0.448 1-1 1z\"></path>\n",
       "</symbol>\n",
       "</defs>\n",
       "</svg>\n",
       "<style>/* CSS stylesheet for displaying xarray objects in jupyterlab.\n",
       " *\n",
       " */\n",
       "\n",
       ":root {\n",
       "  --xr-font-color0: var(--jp-content-font-color0, rgba(0, 0, 0, 1));\n",
       "  --xr-font-color2: var(--jp-content-font-color2, rgba(0, 0, 0, 0.54));\n",
       "  --xr-font-color3: var(--jp-content-font-color3, rgba(0, 0, 0, 0.38));\n",
       "  --xr-border-color: var(--jp-border-color2, #e0e0e0);\n",
       "  --xr-disabled-color: var(--jp-layout-color3, #bdbdbd);\n",
       "  --xr-background-color: var(--jp-layout-color0, white);\n",
       "  --xr-background-color-row-even: var(--jp-layout-color1, white);\n",
       "  --xr-background-color-row-odd: var(--jp-layout-color2, #eeeeee);\n",
       "}\n",
       "\n",
       "html[theme=\"dark\"],\n",
       "html[data-theme=\"dark\"],\n",
       "body[data-theme=\"dark\"],\n",
       "body.vscode-dark {\n",
       "  --xr-font-color0: rgba(255, 255, 255, 1);\n",
       "  --xr-font-color2: rgba(255, 255, 255, 0.54);\n",
       "  --xr-font-color3: rgba(255, 255, 255, 0.38);\n",
       "  --xr-border-color: #1f1f1f;\n",
       "  --xr-disabled-color: #515151;\n",
       "  --xr-background-color: #111111;\n",
       "  --xr-background-color-row-even: #111111;\n",
       "  --xr-background-color-row-odd: #313131;\n",
       "}\n",
       "\n",
       ".xr-wrap {\n",
       "  display: block !important;\n",
       "  min-width: 300px;\n",
       "  max-width: 700px;\n",
       "}\n",
       "\n",
       ".xr-text-repr-fallback {\n",
       "  /* fallback to plain text repr when CSS is not injected (untrusted notebook) */\n",
       "  display: none;\n",
       "}\n",
       "\n",
       ".xr-header {\n",
       "  padding-top: 6px;\n",
       "  padding-bottom: 6px;\n",
       "  margin-bottom: 4px;\n",
       "  border-bottom: solid 1px var(--xr-border-color);\n",
       "}\n",
       "\n",
       ".xr-header > div,\n",
       ".xr-header > ul {\n",
       "  display: inline;\n",
       "  margin-top: 0;\n",
       "  margin-bottom: 0;\n",
       "}\n",
       "\n",
       ".xr-obj-type,\n",
       ".xr-array-name {\n",
       "  margin-left: 2px;\n",
       "  margin-right: 10px;\n",
       "}\n",
       "\n",
       ".xr-obj-type {\n",
       "  color: var(--xr-font-color2);\n",
       "}\n",
       "\n",
       ".xr-sections {\n",
       "  padding-left: 0 !important;\n",
       "  display: grid;\n",
       "  grid-template-columns: 150px auto auto 1fr 0 20px 0 20px;\n",
       "}\n",
       "\n",
       ".xr-section-item {\n",
       "  display: contents;\n",
       "}\n",
       "\n",
       ".xr-section-item input {\n",
       "  display: inline-block;\n",
       "  opacity: 0;\n",
       "  height: 0;\n",
       "}\n",
       "\n",
       ".xr-section-item input + label {\n",
       "  color: var(--xr-disabled-color);\n",
       "}\n",
       "\n",
       ".xr-section-item input:enabled + label {\n",
       "  cursor: pointer;\n",
       "  color: var(--xr-font-color2);\n",
       "}\n",
       "\n",
       ".xr-section-item input:focus + label {\n",
       "  border: 2px solid var(--xr-font-color0);\n",
       "}\n",
       "\n",
       ".xr-section-item input:enabled + label:hover {\n",
       "  color: var(--xr-font-color0);\n",
       "}\n",
       "\n",
       ".xr-section-summary {\n",
       "  grid-column: 1;\n",
       "  color: var(--xr-font-color2);\n",
       "  font-weight: 500;\n",
       "}\n",
       "\n",
       ".xr-section-summary > span {\n",
       "  display: inline-block;\n",
       "  padding-left: 0.5em;\n",
       "}\n",
       "\n",
       ".xr-section-summary-in:disabled + label {\n",
       "  color: var(--xr-font-color2);\n",
       "}\n",
       "\n",
       ".xr-section-summary-in + label:before {\n",
       "  display: inline-block;\n",
       "  content: \"►\";\n",
       "  font-size: 11px;\n",
       "  width: 15px;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       ".xr-section-summary-in:disabled + label:before {\n",
       "  color: var(--xr-disabled-color);\n",
       "}\n",
       "\n",
       ".xr-section-summary-in:checked + label:before {\n",
       "  content: \"▼\";\n",
       "}\n",
       "\n",
       ".xr-section-summary-in:checked + label > span {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       ".xr-section-summary,\n",
       ".xr-section-inline-details {\n",
       "  padding-top: 4px;\n",
       "  padding-bottom: 4px;\n",
       "}\n",
       "\n",
       ".xr-section-inline-details {\n",
       "  grid-column: 2 / -1;\n",
       "}\n",
       "\n",
       ".xr-section-details {\n",
       "  display: none;\n",
       "  grid-column: 1 / -1;\n",
       "  margin-bottom: 5px;\n",
       "}\n",
       "\n",
       ".xr-section-summary-in:checked ~ .xr-section-details {\n",
       "  display: contents;\n",
       "}\n",
       "\n",
       ".xr-array-wrap {\n",
       "  grid-column: 1 / -1;\n",
       "  display: grid;\n",
       "  grid-template-columns: 20px auto;\n",
       "}\n",
       "\n",
       ".xr-array-wrap > label {\n",
       "  grid-column: 1;\n",
       "  vertical-align: top;\n",
       "}\n",
       "\n",
       ".xr-preview {\n",
       "  color: var(--xr-font-color3);\n",
       "}\n",
       "\n",
       ".xr-array-preview,\n",
       ".xr-array-data {\n",
       "  padding: 0 5px !important;\n",
       "  grid-column: 2;\n",
       "}\n",
       "\n",
       ".xr-array-data,\n",
       ".xr-array-in:checked ~ .xr-array-preview {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       ".xr-array-in:checked ~ .xr-array-data,\n",
       ".xr-array-preview {\n",
       "  display: inline-block;\n",
       "}\n",
       "\n",
       ".xr-dim-list {\n",
       "  display: inline-block !important;\n",
       "  list-style: none;\n",
       "  padding: 0 !important;\n",
       "  margin: 0;\n",
       "}\n",
       "\n",
       ".xr-dim-list li {\n",
       "  display: inline-block;\n",
       "  padding: 0;\n",
       "  margin: 0;\n",
       "}\n",
       "\n",
       ".xr-dim-list:before {\n",
       "  content: \"(\";\n",
       "}\n",
       "\n",
       ".xr-dim-list:after {\n",
       "  content: \")\";\n",
       "}\n",
       "\n",
       ".xr-dim-list li:not(:last-child):after {\n",
       "  content: \",\";\n",
       "  padding-right: 5px;\n",
       "}\n",
       "\n",
       ".xr-has-index {\n",
       "  font-weight: bold;\n",
       "}\n",
       "\n",
       ".xr-var-list,\n",
       ".xr-var-item {\n",
       "  display: contents;\n",
       "}\n",
       "\n",
       ".xr-var-item > div,\n",
       ".xr-var-item label,\n",
       ".xr-var-item > .xr-var-name span {\n",
       "  background-color: var(--xr-background-color-row-even);\n",
       "  margin-bottom: 0;\n",
       "}\n",
       "\n",
       ".xr-var-item > .xr-var-name:hover span {\n",
       "  padding-right: 5px;\n",
       "}\n",
       "\n",
       ".xr-var-list > li:nth-child(odd) > div,\n",
       ".xr-var-list > li:nth-child(odd) > label,\n",
       ".xr-var-list > li:nth-child(odd) > .xr-var-name span {\n",
       "  background-color: var(--xr-background-color-row-odd);\n",
       "}\n",
       "\n",
       ".xr-var-name {\n",
       "  grid-column: 1;\n",
       "}\n",
       "\n",
       ".xr-var-dims {\n",
       "  grid-column: 2;\n",
       "}\n",
       "\n",
       ".xr-var-dtype {\n",
       "  grid-column: 3;\n",
       "  text-align: right;\n",
       "  color: var(--xr-font-color2);\n",
       "}\n",
       "\n",
       ".xr-var-preview {\n",
       "  grid-column: 4;\n",
       "}\n",
       "\n",
       ".xr-index-preview {\n",
       "  grid-column: 2 / 5;\n",
       "  color: var(--xr-font-color2);\n",
       "}\n",
       "\n",
       ".xr-var-name,\n",
       ".xr-var-dims,\n",
       ".xr-var-dtype,\n",
       ".xr-preview,\n",
       ".xr-attrs dt {\n",
       "  white-space: nowrap;\n",
       "  overflow: hidden;\n",
       "  text-overflow: ellipsis;\n",
       "  padding-right: 10px;\n",
       "}\n",
       "\n",
       ".xr-var-name:hover,\n",
       ".xr-var-dims:hover,\n",
       ".xr-var-dtype:hover,\n",
       ".xr-attrs dt:hover {\n",
       "  overflow: visible;\n",
       "  width: auto;\n",
       "  z-index: 1;\n",
       "}\n",
       "\n",
       ".xr-var-attrs,\n",
       ".xr-var-data,\n",
       ".xr-index-data {\n",
       "  display: none;\n",
       "  background-color: var(--xr-background-color) !important;\n",
       "  padding-bottom: 5px !important;\n",
       "}\n",
       "\n",
       ".xr-var-attrs-in:checked ~ .xr-var-attrs,\n",
       ".xr-var-data-in:checked ~ .xr-var-data,\n",
       ".xr-index-data-in:checked ~ .xr-index-data {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       ".xr-var-data > table {\n",
       "  float: right;\n",
       "}\n",
       "\n",
       ".xr-var-name span,\n",
       ".xr-var-data,\n",
       ".xr-index-name div,\n",
       ".xr-index-data,\n",
       ".xr-attrs {\n",
       "  padding-left: 25px !important;\n",
       "}\n",
       "\n",
       ".xr-attrs,\n",
       ".xr-var-attrs,\n",
       ".xr-var-data,\n",
       ".xr-index-data {\n",
       "  grid-column: 1 / -1;\n",
       "}\n",
       "\n",
       "dl.xr-attrs {\n",
       "  padding: 0;\n",
       "  margin: 0;\n",
       "  display: grid;\n",
       "  grid-template-columns: 125px auto;\n",
       "}\n",
       "\n",
       ".xr-attrs dt,\n",
       ".xr-attrs dd {\n",
       "  padding: 0;\n",
       "  margin: 0;\n",
       "  float: left;\n",
       "  padding-right: 10px;\n",
       "  width: auto;\n",
       "}\n",
       "\n",
       ".xr-attrs dt {\n",
       "  font-weight: normal;\n",
       "  grid-column: 1;\n",
       "}\n",
       "\n",
       ".xr-attrs dt:hover span {\n",
       "  display: inline-block;\n",
       "  background: var(--xr-background-color);\n",
       "  padding-right: 10px;\n",
       "}\n",
       "\n",
       ".xr-attrs dd {\n",
       "  grid-column: 2;\n",
       "  white-space: pre-wrap;\n",
       "  word-break: break-all;\n",
       "}\n",
       "\n",
       ".xr-icon-database,\n",
       ".xr-icon-file-text2,\n",
       ".xr-no-icon {\n",
       "  display: inline-block;\n",
       "  vertical-align: middle;\n",
       "  width: 1em;\n",
       "  height: 1.5em !important;\n",
       "  stroke-width: 0;\n",
       "  stroke: currentColor;\n",
       "  fill: currentColor;\n",
       "}\n",
       "</style><pre class='xr-text-repr-fallback'>&lt;xarray.DataArray &#x27;observed&#x27; (ensemble: 3, time: 5)&gt; Size: 120B\n",
       "array([[0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0.]])\n",
       "Coordinates:\n",
       "  * ensemble  (ensemble) &lt;U9 108B &#x27;Ensemble1&#x27; &#x27;Ensemble2&#x27; &#x27;Ensemble3&#x27;\n",
       "  * time      (time) datetime64[ns] 40B 2024-01-01 2024-01-02 ... 2024-01-05</pre><div class='xr-wrap' style='display:none'><div class='xr-header'><div class='xr-obj-type'>xarray.DataArray</div><div class='xr-array-name'>'observed'</div><ul class='xr-dim-list'><li><span class='xr-has-index'>ensemble</span>: 3</li><li><span class='xr-has-index'>time</span>: 5</li></ul></div><ul class='xr-sections'><li class='xr-section-item'><div class='xr-array-wrap'><input id='section-4c355a5c-3e7c-4685-8692-2624b3b40538' class='xr-array-in' type='checkbox' checked><label for='section-4c355a5c-3e7c-4685-8692-2624b3b40538' title='Show/hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-array-preview xr-preview'><span>0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0</span></div><div class='xr-array-data'><pre>array([[0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0.]])</pre></div></div></li><li class='xr-section-item'><input id='section-206dac74-c9fa-467a-afec-4154fbf512df' class='xr-section-summary-in' type='checkbox'  checked><label for='section-206dac74-c9fa-467a-afec-4154fbf512df' class='xr-section-summary' >Coordinates: <span>(2)</span></label><div class='xr-section-inline-details'></div><div class='xr-section-details'><ul class='xr-var-list'><li class='xr-var-item'><div class='xr-var-name'><span class='xr-has-index'>ensemble</span></div><div class='xr-var-dims'>(ensemble)</div><div class='xr-var-dtype'>&lt;U9</div><div class='xr-var-preview xr-preview'>&#x27;Ensemble1&#x27; &#x27;Ensemble2&#x27; &#x27;Ensemble3&#x27;</div><input id='attrs-bf7d8c78-d152-4510-a3cf-df8e5563812d' class='xr-var-attrs-in' type='checkbox' disabled><label for='attrs-bf7d8c78-d152-4510-a3cf-df8e5563812d' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-ebc17943-b46f-437d-981a-0ab35972ea50' class='xr-var-data-in' type='checkbox'><label for='data-ebc17943-b46f-437d-981a-0ab35972ea50' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'></dl></div><div class='xr-var-data'><pre>array([&#x27;Ensemble1&#x27;, &#x27;Ensemble2&#x27;, &#x27;Ensemble3&#x27;], dtype=&#x27;&lt;U9&#x27;)</pre></div></li><li class='xr-var-item'><div class='xr-var-name'><span class='xr-has-index'>time</span></div><div class='xr-var-dims'>(time)</div><div class='xr-var-dtype'>datetime64[ns]</div><div class='xr-var-preview xr-preview'>2024-01-01 ... 2024-01-05</div><input id='attrs-b70cce6c-d4b4-44d7-ac97-02cf87f4907a' class='xr-var-attrs-in' type='checkbox' disabled><label for='attrs-b70cce6c-d4b4-44d7-ac97-02cf87f4907a' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-ebe35a4b-a06e-4e8f-92f6-cc593c0777d7' class='xr-var-data-in' type='checkbox'><label for='data-ebe35a4b-a06e-4e8f-92f6-cc593c0777d7' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'></dl></div><div class='xr-var-data'><pre>array([&#x27;2024-01-01T00:00:00.000000000&#x27;, &#x27;2024-01-02T00:00:00.000000000&#x27;,\n",
       "       &#x27;2024-01-03T00:00:00.000000000&#x27;, &#x27;2024-01-04T00:00:00.000000000&#x27;,\n",
       "       &#x27;2024-01-05T00:00:00.000000000&#x27;], dtype=&#x27;datetime64[ns]&#x27;)</pre></div></li></ul></div></li><li class='xr-section-item'><input id='section-7481ddfe-7a95-4ca7-bc1c-a629d4e5f21c' class='xr-section-summary-in' type='checkbox'  ><label for='section-7481ddfe-7a95-4ca7-bc1c-a629d4e5f21c' class='xr-section-summary' >Indexes: <span>(2)</span></label><div class='xr-section-inline-details'></div><div class='xr-section-details'><ul class='xr-var-list'><li class='xr-var-item'><div class='xr-index-name'><div>ensemble</div></div><div class='xr-index-preview'>PandasIndex</div><input type='checkbox' disabled/><label></label><input id='index-e096cc4c-0955-491d-b528-9d97e4ab01cf' class='xr-index-data-in' type='checkbox'/><label for='index-e096cc4c-0955-491d-b528-9d97e4ab01cf' title='Show/Hide index repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-index-data'><pre>PandasIndex(Index([&#x27;Ensemble1&#x27;, &#x27;Ensemble2&#x27;, &#x27;Ensemble3&#x27;], dtype=&#x27;object&#x27;, name=&#x27;ensemble&#x27;))</pre></div></li><li class='xr-var-item'><div class='xr-index-name'><div>time</div></div><div class='xr-index-preview'>PandasIndex</div><input type='checkbox' disabled/><label></label><input id='index-0662a8be-f83c-4876-a2a2-23e768d298bb' class='xr-index-data-in' type='checkbox'/><label for='index-0662a8be-f83c-4876-a2a2-23e768d298bb' title='Show/Hide index repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-index-data'><pre>PandasIndex(DatetimeIndex([&#x27;2024-01-01&#x27;, &#x27;2024-01-02&#x27;, &#x27;2024-01-03&#x27;, &#x27;2024-01-04&#x27;,\n",
       "               &#x27;2024-01-05&#x27;],\n",
       "              dtype=&#x27;datetime64[ns]&#x27;, name=&#x27;time&#x27;, freq=&#x27;D&#x27;))</pre></div></li></ul></div></li><li class='xr-section-item'><input id='section-7b2b1de0-6fd9-4428-954d-402b34d59fd5' class='xr-section-summary-in' type='checkbox' disabled ><label for='section-7b2b1de0-6fd9-4428-954d-402b34d59fd5' class='xr-section-summary'  title='Expand/collapse section'>Attributes: <span>(0)</span></label><div class='xr-section-inline-details'></div><div class='xr-section-details'><dl class='xr-attrs'></dl></div></li></ul></div></div>"
      ],
      "text/plain": [
       "<xarray.DataArray 'observed' (ensemble: 3, time: 5)> Size: 120B\n",
       "array([[0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0.]])\n",
       "Coordinates:\n",
       "  * ensemble  (ensemble) <U9 108B 'Ensemble1' 'Ensemble2' 'Ensemble3'\n",
       "  * time      (time) datetime64[ns] 40B 2024-01-01 2024-01-02 ... 2024-01-05"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We can briefly check the zero obs hypothesis\n",
    "obs_xr.var([\"station\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 7: 3D Array: Time, Station and Lead-time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "\n",
    "\n",
    "def create_synthetic_deterministic_data():\n",
    "    # Define dimensions\n",
    "    time = pd.date_range(\"2024-01-01\", \"2024-01-31\", freq=\"D\")\n",
    "    stations = [\"Station1\", \"Station2\", \"Station3\", \"Station4\", \"Station5\"]\n",
    "    lead_times_forecast = np.arange(1, 8)  # Lead times from 1 to 7 for forecast\n",
    "    lead_times_observed = np.array([1])  # Lead time of 1 day for observed data\n",
    "\n",
    "    # Generate synthetic hydrograph data\n",
    "    np.random.seed(0)  # For reproducibility\n",
    "\n",
    "    # Base sine wave to simulate periodic streamflow variations\n",
    "    days = len(time)\n",
    "    base_flow = 150 + 50 * np.sin(2 * np.pi * np.arange(days) / days)  # Mean of 150, amplitude of 50\n",
    "\n",
    "    # Reshape base_flow to match dimensions (31, 1, 1) for broadcasting\n",
    "    base_flow = base_flow[:, np.newaxis, np.newaxis]\n",
    "\n",
    "    # Adding random fluctuations around the base flow for forecast and observed data\n",
    "    forecast_data = np.clip(base_flow + 20 * np.random.randn(days, len(stations), len(lead_times_forecast)), 0, 300)\n",
    "    observed_data = np.clip(base_flow + 20 * np.random.randn(days, len(stations), len(lead_times_observed)), 0, 300)\n",
    "\n",
    "    # Create forecast DataArray\n",
    "    forecast_da = xr.DataArray(\n",
    "        forecast_data,\n",
    "        coords={\"time\": time, \"station\": stations, \"lead_time\": lead_times_forecast},\n",
    "        dims=[\"time\", \"station\", \"lead_time\"],\n",
    "        name=\"forecast\",\n",
    "    )\n",
    "\n",
    "    # Create observed DataArray\n",
    "    observed_da = xr.DataArray(\n",
    "        observed_data,\n",
    "        coords={\"time\": time, \"station\": stations, \"lead_time\": lead_times_observed},\n",
    "        dims=[\"time\", \"station\", \"lead_time\"],\n",
    "        name=\"observed\",\n",
    "    )\n",
    "\n",
    "    return forecast_da, observed_da"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "obs shape: Frozen({'time': 31, 'station': 5, 'lead_time': 1})\n",
      "fcst shape: Frozen({'time': 31, 'station': 5, 'lead_time': 7})\n"
     ]
    }
   ],
   "source": [
    "# Display the DataArrays\n",
    "# Create forecast and observed DataArrays\n",
    "forecast_da, observed_da = create_synthetic_deterministic_data()\n",
    "print(f\"obs shape: {observed_da.sizes}\")\n",
    "print(f\"fcst shape: {forecast_da.sizes}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NSE Calculation along Lead-time\n",
    "\n",
    "So far we've been only passing a string to `reduce_dims`, as mentioned in the introduction of this tutorial, the indexers can span multiple dimensions. Suppose we would like to find NSE for each lead time, we simply need to pass `reduce_dims=(\"station\", \"time\")` alternatively, `preserve_dims=\"lead_time\"` should also work. Before doing so, we need to broadcast the two arrays prior to computations. Normally, this will happen automatically - but fill it with NaNs when broadcasted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "NaN entries with xarray broadcasting:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 0, 31, 31, 31, 31, 31, 31],\n",
       "       [ 0, 31, 31, 31, 31, 31, 31],\n",
       "       [ 0, 31, 31, 31, 31, 31, 31],\n",
       "       [ 0, 31, 31, 31, 31, 31, 31],\n",
       "       [ 0, 31, 31, 31, 31, 31, 31]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "NaN entries with xarray broadcasting:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(31, 5, 1)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "NaN entries with `.values` and numpy broadcasting:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "shape when doing a basic numpy subtraction instead\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(31, 5, 7)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"\\n\\nNaN entries with xarray broadcasting:\")\n",
    "display(sum(np.isnan(xr.broadcast(forecast_da, observed_da)[1].values)))\n",
    "print(\"\\n\\nNaN entries with xarray broadcasting:\")\n",
    "display((forecast_da - observed_da).shape)\n",
    "print(\"\\n\\nNaN entries with `.values` and numpy broadcasting:\")\n",
    "display(sum(np.isnan(np.broadcast_to(observed_da, forecast_da.shape))))\n",
    "print(\"\\nshape when doing a basic numpy subtraction instead\")\n",
    "display((forecast_da.values - observed_da.values).shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Proper Broadcasting\n",
    "\n",
    "The reason this happens is because of the strict coordinate defintions. To circumvent this we actually need to use numpy's broadcast method, so that we are dealing with an attribute-less data-array. Since `nse` relies on `mse` for performing any computations under-the-hood, where the latter relies on using `xarray` for computational API calls rather than `numpy`. If we do want to mimic `numpy`'s method we just have to use `numpy` to call broadcast instead.\n",
    "\n",
    "> **Caution:**\n",
    ">\n",
    "> Using numpy for broadcasting will almost certainly load everything to memory. However, unlike `xarray` which relies on merge strategies, numpy basically repeats data if the dimensions are compatible.\n",
    ">\n",
    "> In any case - broadcasting is not always trivial - especially for large datasets. In particular, `nse` (and by extension `mse`) do not guarantee operations are broadcasted to variables and dimensions that do not match between the `obs`, `fcst` and optionally `weights` arguments. Instead, they trim the operations to coordinates that are compatible. This is _intentional_, as there is no obvious default broadcasting option (both broadcasting by `nan`-filling and broadcasting using vectorisation (or replication) are viable for different scenarios).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "broadcasted obs shape:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Frozen({'time': 31, 'station': 5, 'lead_time': 7})"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Check index 0 against index 1 have the same repeated values\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(True)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Check index 0 against last index (-1) have the same repeated values\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(True)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Now we have repeating obs... let's compute NSE\n",
      "\n",
      "\n",
      "------------------------------\n",
      " NSE broadcasted using xarray\n",
      "------------------------------\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.57235442])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note that this still works, but we only get a single output - for lead time 1...\n",
      "\n",
      "-----------------------------\n",
      " NSE broadcasted using numpy\n",
      "-----------------------------\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.57235442, 0.5626212 , 0.51905304, 0.45527247, 0.60358371,\n",
       "       0.53880208, 0.50453494])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "...However using the numpy based broadcasting we get all 7 leadtimes\n",
      "Note we could have also used `preserve_dims='lead_time'` to get the same result:\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.57235442, 0.5626212 , 0.51905304, 0.45527247, 0.60358371,\n",
       "       0.53880208, 0.50453494])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "observed_np_broadcast = np.broadcast_to(observed_da, forecast_da.shape)\n",
    "observed_da_broadcast = observed_da.broadcast_like(forecast_da)\n",
    "observed_da_broadcast = observed_da_broadcast.copy(data=observed_np_broadcast)\n",
    "\n",
    "# to breakdown the above:\n",
    "# - np.broadcast_to: takes the observed_da and broadcasts it to the forecast_da's shape - it repeats the data if compatible.\n",
    "# - DataArray.broadcast_like: is a relatively cheap operation that just setsup extra space to match the forecast data array's shape\n",
    "# - .copy: creates a shallow copy, but it's mostly used for its \"data\" argument which can be used to update the entries in the newly broadcasted array.\n",
    "# Now if we look at the shape:\n",
    "print(\"\\nbroadcasted obs shape:\")\n",
    "display(observed_da_broadcast.sizes)\n",
    "print(\"\\nCheck index 0 against index 1 have the same repeated values\")\n",
    "display(np.all(observed_da_broadcast[:,:,0] == observed_da_broadcast[:,:,1]).values)\n",
    "print(\"\\nCheck index 0 against last index (-1) have the same repeated values\")\n",
    "display(np.all(observed_da_broadcast[:,:,0] == observed_da_broadcast[:,:,-1]).values)\n",
    "print(\"\\nNow we have repeating obs... let's compute NSE\\n\")\n",
    "\n",
    "print(\"\\n------------------------------\")\n",
    "print(\" NSE broadcasted using xarray\")\n",
    "print(\"------------------------------\\n\")\n",
    "from scores.continuous import mse\n",
    "\n",
    "# note: see how we can specify reduce_dims on an array of dimensions instead of a single string\n",
    "display(nse(forecast_da, observed_da, reduce_dims=[\"time\", \"station\"]).values)\n",
    "print(\"Note that this still works, but we only get a single output - for lead time 1...\")\n",
    "\n",
    "print(\"\\n-----------------------------\")\n",
    "print(\" NSE broadcasted using numpy\")\n",
    "print(\"-----------------------------\\n\")\n",
    "display(nse(forecast_da, observed_da_broadcast, reduce_dims=[\"time\", \"station\"]).values)\n",
    "print(\"\\n\\n...However using the numpy based broadcasting we get all 7 leadtimes\")\n",
    "print(\"Note we could have also used `preserve_dims='lead_time'` to get the same result:\\n\\n\")\n",
    "display(nse(forecast_da, observed_da_broadcast, preserve_dims=\"lead_time\").values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Is `nse` causing the quirky broadcasting or is it `mse`?**\n<br>",
    "\n",
    "_(spoiler: neither)_\n",
    "\n",
    "As mentioned `nse` uses `mse` under the hood for consistency. We can show that this broadcasting behaviour is not unique to `nse` by replacing those operations with `mse`.\n",
    "\n",
    "In any case - the answer is neither. In fact it has nothing to do with `scores` - it's a fundamental between how `numpy` and `xarray` decide to do broadcasting. Noting that `scalars` are exceptions to the rule."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "NSE - leadtime just has one value\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.57235442])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "MSE - same deal\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([707.48065628])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "taking the mean difference between two datasets - same deal\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([-2.36811031])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Subtracting a scalar is fine though\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([145.02236298, 144.6017132 , 145.24734202, 143.92826001,\n",
       "       143.55788964, 144.84651296, 142.14080276])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from scores.continuous import mse\n",
    "\n",
    "print(\"\\nNSE - leadtime just has one value\")\n",
    "display(nse(forecast_da, observed_da, reduce_dims=[\"time\", \"station\"]).values)\n",
    "\n",
    "print(\"\\nMSE - same deal\")\n",
    "display(mse(forecast_da, observed_da, reduce_dims=[\"time\", \"station\"]).values)\n",
    "\n",
    "print(\"\\ntaking the mean difference between two datasets - same deal\")\n",
    "display((forecast_da - observed_da).mean([\"time\", \"station\"]).values)\n",
    "\n",
    "print(\"\\nSubtracting a scalar is fine though\")\n",
    "display((forecast_da - 5).mean([\"time\", \"station\"]).values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 8: 4D Array: Time, Station, lead times and ensemble\n",
    "\n",
    "The following example shows NSE computed on ensemble forecasts that are synthetically generated. We would still hit the broadcasting issue above, since the observed data will not match the dimensions of the ensembles and to compute the scores we want to use `numpy`'s style of replicating data. This example deals with this by looping through the ensembles, iteratively computing NSE for each ensemble to avoid memory bloat. Broadcasted operations will then apply to any remaining dimensions that match in size between obs and fcst."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_synthetic_ensemble_data():\n",
    "    # Define dimensions\n",
    "    time = pd.date_range(\"2024-01-01\", \"2024-01-31\", freq=\"D\")\n",
    "    stations = [\"Station1\", \"Station2\", \"Station3\", \"Station4\", \"Station5\"]\n",
    "    lead_times_forecast = np.arange(1, 8)  # Lead times from 1 to 7 for forecast\n",
    "    lead_times_observed = np.array([1])  # Lead time of 1 day for observed data\n",
    "    ensemble = [f\"Ensemble{i}\" for i in range(1, 21)]  # Ensemble members from Ensemble1 to Ensemble20\n",
    "\n",
    "    # Generate synthetic hydrograph data\n",
    "    np.random.seed(0)  # For reproducibility\n",
    "\n",
    "    # Create base flow as a constant value of 30 cumec\n",
    "    base_flow = 30\n",
    "\n",
    "    # Adding random fluctuations around the base flow for forecast and observed data\n",
    "    forecast_data = base_flow + np.random.randint(\n",
    "        0, 301, size=(len(time), len(stations), len(lead_times_forecast), len(ensemble))\n",
    "    )\n",
    "    observed_data = base_flow + np.random.randint(0, 301, size=(len(time), len(stations), len(lead_times_observed)))\n",
    "\n",
    "    # Clip the data to ensure it stays within a certain range\n",
    "    forecast_data = np.clip(forecast_data, 0, 300)\n",
    "    observed_data = np.clip(observed_data, 0, 300)\n",
    "\n",
    "    # Create forecast DataArray\n",
    "    forecast_da = xr.DataArray(\n",
    "        forecast_data,\n",
    "        coords={\"time\": time, \"station\": stations, \"lead_time\": lead_times_forecast, \"ensemble\": ensemble},\n",
    "        dims=[\"time\", \"station\", \"lead_time\", \"ensemble\"],\n",
    "        name=\"forecast\",\n",
    "    )\n",
    "\n",
    "    # Create observed DataArray\n",
    "    observed_da = xr.DataArray(\n",
    "        observed_data,\n",
    "        coords={\"time\": time, \"station\": stations, \"lead_time\": lead_times_observed},\n",
    "        dims=[\"time\", \"station\", \"lead_time\"],\n",
    "        name=\"observed\",\n",
    "    )\n",
    "\n",
    "    return forecast_da, observed_da"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Frozen({'time': 31, 'station': 5, 'lead_time': 7, 'ensemble': 20})"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Frozen({'time': 31, 'station': 5, 'lead_time': 1})"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create forecast and observed DataArrays\n",
    "forecast_ensemble_da, observed_da = create_synthetic_ensemble_data()\n",
    "\n",
    "# Display the DataArrays\n",
    "display(forecast_ensemble_da.sizes)\n",
    "display(observed_da.sizes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize an empty list to store results\n",
    "results_list = []\n",
    "\n",
    "# Iterate through each ensemble member and lead time\n",
    "for imember in forecast_ensemble_da[\"ensemble\"].values:\n",
    "    for ilead in forecast_ensemble_da[\"lead_time\"].values:\n",
    "        # Select the forecast data for the current ensemble member and lead time\n",
    "        cur_fcst_da = forecast_ensemble_da.sel(ensemble=imember, lead_time=ilead)\n",
    "\n",
    "        # Calculate NSE value for the selected forecast data and observed data\n",
    "        nse_value = nse(cur_fcst_da, observed_da).values\n",
    "\n",
    "        # Append the results as a dictionary to the list\n",
    "        results_list.append({\"ensemble\": imember, \"lead_time\": ilead, \"NSE\": nse_value})\n",
    "\n",
    "# Create a DataFrame from the list of dictionaries\n",
    "nse_results = pd.DataFrame(results_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    ensemble  lead_time                  NSE\n",
      "0  Ensemble1          1  -1.1721371704833192\n",
      "1  Ensemble1          2  -1.0448237401444582\n",
      "2  Ensemble1          3   -1.060897482889457\n"
     ]
    }
   ],
   "source": [
    "# Print the DataFrame\n",
    "print(nse_results.head(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise for the Reader\n",
    "\n",
    "The above can also be done using `xarrays`'s `map_blocks` or `apply_ufunc` methods - which may reduce the load on memory further by using `dask` to partition and compute chunks more efficiently.\n",
    "\n",
    "> **Note:** that dask should not be the first solution and a simple loop like above may usually accomplish things sufficiently (and explicitly) - even for very large datasets - noting that xarray/netcdf4 loads data lazily with or without dask. `dask` on the other hand is useful when dealing with distributed compute and storage.\n",
    ">\n",
    "> Fore more info see:\n",
    "> - *dask guidelines* - in particular section on start small: https://docs.dask.org/en/stable/best-practices.html#start-small\n",
    "> - *xarray ufunc/map_blocks* - in particular any tutorials referenced: https://docs.xarray.dev/en/stable/user-guide/dask.html#dask-automatic-parallelization\n",
    "> - *numpy broadcasting* - these are helpful integrations to the underlying ufunc allowing observations to be broadcast to forecast ensembles while still being compatible with the above xarray functions: https://numpy.org/doc/stable/reference/generated/numpy.broadcast_arrays.html#numpy.broadcast_arrays"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Other Things to Try\n",
    "\n",
    "There are several variants of NSE that are useful for particular applications, see: https://en.wikipedia.org/wiki/Nash%E2%80%93Sutcliffe_model_efficiency_coefficient\n",
    "- Scores currently supports the use of `weights`. This allows the user to calculate `wNSE`, which is typically scaled by the `obs` itself. See: [Hundecha and Bárdossy (2004)](https://doi.org/10.1016/j.jhydrol.2004.01.002).\n",
    "- `weights` can also be used as \"selectors\" by specifying binary values (in this case `1 => include datum` or `np.nan => exclude datum`. This is useful for slicing hydrographs by their observation values and accumulating over the resultant extents.\n",
    "- `NNSE` a variant of NSE that works with machine learning optimisation functions.\n",
    "- `LNSE` logarithmic processing of observation and forecasts *prior* to computing NSE for better representation of smaller values.\n",
    "\n",
    "\n",
    "Most of the above variations can be computed either by:\n",
    "- preprocessing the observations/forecast,\n",
    "- composing the NSE computation with another function,\n",
    "- or scaling using the `weights` input argument.\n"
   ]
  }
],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
