{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quantile Loss (Score)\n",
    "\n",
    "[Geinting, T. (2011). Making and evaluating point forecasts, Journal of the American Statistical Association, 106(494), 746-762.](https://www.tandfonline.com/doi/abs/10.1198/jasa.2011.r10138)\n",
    "\n",
    "Quantile loss (score) is a consistent scoring function for an $\\alpha$-quantile forecast, where $\\alpha \\in (0, 1)$. Quantile loss function is also used in Machine Learning, in quantile regression, which focuses on estimating different quantiles of the conditional distributution of the response variable. Please note that quantiles are often referred to as value-at-risk in finance.\n",
    "\n",
    "The quantile loss function is defined as:\n",
    "\n",
    "$$ S(x, y) = \\begin{cases} \n",
    "\\alpha \\cdot (y - x) & \\text{if } y \\geq x \\\\\n",
    "(\\alpha - 1) \\cdot (y - x) & \\text{if } y < x \n",
    "\\end{cases} $$\n",
    "\n",
    "where $S$ is the scoring function (here quantile loss), $x$ and $y$ are forecast and observation, respectively.\n",
    "\n",
    "For more information about quantile loss function, please read [Geinting, T. (2011)](https://www.tandfonline.com/doi/abs/10.1198/jasa.2011.r10138).\n",
    "\n",
    "\n",
    "Now let's look at an example where we demonstrate how to use quantile score:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scores.continuous import quantile_score\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example, we create two synthetic forecasts and observation data with dimensions of `('lat', 'lon', 'time')`. One forecast systems is better at targeting the median (FCST_50), while the other one is better at targeting the 90th percentile (FCST_90)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "lat = np.linspace(-90, 90, 10)\n",
    "lon = np.linspace(-180, 180, 20)\n",
    "times = pd.date_range('2023-11-19', periods=5)\n",
    "forecast_90th = np.random.uniform(0.7, 1.0, size=(len(lat), len(lon), len(times)))\n",
    "forecast_90th_da = xr.DataArray(\n",
    "    forecast_90th,\n",
    "    dims=('lat', 'lon', 'time'),\n",
    "    coords={'lat': lat, 'lon': lon, 'time': times}\n",
    ")\n",
    "forecast_50th = np.random.uniform(0.3, 0.6, size=(len(lat), len(lon), len(times)))\n",
    "forecast_50th_da = xr.DataArray(\n",
    "    forecast_50th,\n",
    "    dims=('lat', 'lon', 'time'),\n",
    "    coords={'lat': lat, 'lon': lon, 'time': times}\n",
    ")\n",
    "\n",
    "obs = np.random.rand(len(lat), len(lon), len(times))\n",
    "obs_da = xr.DataArray(\n",
    "    obs,\n",
    "    dims=('lat', 'lon', 'time'),\n",
    "    coords={'lat': lat, 'lon': lon, 'time': times}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we want to calculate the quantile score of these two forecast systems for the median ($\\alpha=0.5$) and 90th percentile ($\\alpha=0.9$). In the `quantile_score` function, users can either calculate the overall score (i.e., `preserve_dims=reduce_dims=None`), so it will return one value that is the overall mean generalised piecewise linear (GPL) score, or calculate the score over specific dimension(s) by using `preserve_dims` or `reduce_dims` arguments. First let's calculate the overall score of these forecasts for their targeted quantile (you always need to ensure that verification is aligned with the forecast definition):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall GPL score for:\n",
      " FCST_50 (targeted at 50th percentile):  0.131\n",
      " FCST_90 (targeted at 90th percentile): 0.049\n"
     ]
    }
   ],
   "source": [
    "overall_qs_med = quantile_score(fcst=forecast_50th_da, obs=obs_da, alpha=0.5)\n",
    "overall_qs_90th = quantile_score(fcst=forecast_90th_da, obs=obs_da, alpha=0.9)\n",
    "print(\n",
    "    f\"Overall GPL score for:\"\n",
    "    f\"\\n FCST_50 (targeted at 50th percentile):  {np.round(overall_qs_med.values, 3)}\"\n",
    "    f\"\\n FCST_90 (targeted at 90th percentile): {np.round(overall_qs_90th.values, 3)}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's use `preserve_dims=['time']` in our calculation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantile score values by preserving time dimension\n",
      " FCST_50 (targeted at 50th percentile):  [0.136 0.125 0.137 0.129 0.129]\n",
      " FCST_90 (targeted at 90th percentile): [0.049 0.047 0.054 0.048 0.049]\n"
     ]
    }
   ],
   "source": [
    "overall_qs_med_time = quantile_score(fcst=forecast_50th_da, obs=obs_da, alpha=0.5, preserve_dims=['time'])\n",
    "overall_qs_90th_time = quantile_score(fcst=forecast_90th_da, obs=obs_da, alpha=0.9, preserve_dims=['time'])\n",
    "print(\n",
    "    f\"Quantile score values by preserving time dimension\"\n",
    "    f\"\\n FCST_50 (targeted at 50th percentile):  {np.round(overall_qs_med_time.values, 3)}\"\n",
    "    f\"\\n FCST_90 (targeted at 90th percentile): {np.round(overall_qs_90th_time.values, 3)}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please note that user have the option to input an array of weights within `quantile_score` to compute a weighted average score. An example scenario could involve assigning weights to regions based on their population when computing the quantile score. Following is an example of using weights, where we give a larger weights to a few locations (lat, lon)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPL scores by preserving 'time' dimension and using an array of weights are:\n",
      " FCST_50 (targeted at 50th percentile): [0.136 0.125 0.137 0.138 0.142],\n",
      " FCST_90 (targeted at 90th percentile): [0.049 0.047 0.054 0.053 0.054]\n"
     ]
    }
   ],
   "source": [
    "weights_data = np.ones_like(obs)\n",
    "weights_data[:, -2:, -2:] = 2\n",
    "weights = xr.DataArray(weights_data, dims=('lat', 'lon', 'time'))\n",
    "weighted_time_loss_score_med = quantile_score(\n",
    "    fcst=forecast_50th_da, obs=obs_da, alpha=0.5, preserve_dims=['time'], weights=weights\n",
    ")\n",
    "weighted_time_loss_score_90th = quantile_score(\n",
    "    fcst=forecast_90th_da, obs=obs_da, alpha=0.9, preserve_dims=['time'], weights=weights\n",
    ")\n",
    "print(\n",
    "    f\"GPL scores by preserving 'time' dimension and using an array of weights are:\"\n",
    "    f\"\\n FCST_50 (targeted at 50th percentile): {np.round(weighted_time_loss_score_med.values, 3)},\"\n",
    "    f\"\\n FCST_90 (targeted at 90th percentile): {np.round(weighted_time_loss_score_90th.values, 3)}\"\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
