{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "18f07086-30d0-43ee-b560-f894b00508f3",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'reduce_dims' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mscores\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcategorical\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mxarray\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mxr\u001b[39;00m\n",
      "File \u001b[0;32m~/dev/proj/scores/src/scores/__init__.py:6\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;124;03mThe philosphy is to import the public API during the init phase rather than leaving it to the user\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# pylint: disable=E0603\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mscores\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcategorical\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mscores\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcontinuous\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mscores\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfunctions\u001b[39;00m\n",
      "File \u001b[0;32m~/dev/proj/scores/src/scores/categorical/__init__.py:8\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;124;03mImport the functions from the implementations into the public API\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mscores\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcategorical\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbinary_impl\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m      5\u001b[0m     probability_of_detection,\n\u001b[1;32m      6\u001b[0m     probability_of_false_detection,\n\u001b[1;32m      7\u001b[0m )\n\u001b[0;32m----> 8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mscores\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcategorical\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcontingency_impl\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m      9\u001b[0m     BinaryContingencyTable,\n\u001b[1;32m     10\u001b[0m     ThresholdEventOperator,\n\u001b[1;32m     11\u001b[0m     accuracy,\n\u001b[1;32m     12\u001b[0m )\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mscores\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcategorical\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmulticategorical_impl\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m firm\n\u001b[1;32m     15\u001b[0m __all__ \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m     16\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprobability_of_detection\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     17\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprobability_of_false_detection\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     22\u001b[0m ]\n",
      "File \u001b[0;32m~/dev/proj/scores/src/scores/categorical/contingency_impl.py:202\u001b[0m\n\u001b[1;32m    196\u001b[0m         s \u001b[38;5;241m=\u001b[39m cd[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtn_count\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m/\u001b[39m (cd[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtn_count\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m+\u001b[39m cd[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfp_count\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m    197\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m s                \n\u001b[0;32m--> 202\u001b[0m \u001b[38;5;28;43;01mclass\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;21;43;01mBinaryContingencyTable\u001b[39;49;00m\u001b[43m(\u001b[49m\u001b[43mBasicContingencyTable\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m    203\u001b[0m \u001b[38;5;250;43m    \u001b[39;49m\u001b[38;5;124;43;03m\"\"\"\u001b[39;49;00m\n\u001b[1;32m    204\u001b[0m \u001b[38;5;124;43;03m    At each location, the value will either be:\u001b[39;49;00m\n\u001b[1;32m    205\u001b[0m \u001b[38;5;124;43;03m     - A true positive\u001b[39;49;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[38;5;124;43;03m    ratios involved. \u001b[39;49;00m\n\u001b[1;32m    219\u001b[0m \u001b[38;5;124;43;03m    \"\"\"\u001b[39;49;00m\n\u001b[1;32m    221\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mdef\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mforecast_events\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mobserved_events\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m    222\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# type checking goes here\u001b[39;49;00m\n",
      "File \u001b[0;32m~/dev/proj/scores/src/scores/categorical/contingency_impl.py:238\u001b[0m, in \u001b[0;36mBinaryContingencyTable\u001b[0;34m()\u001b[0m\n\u001b[1;32m    235\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfn_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfn\u001b[38;5;241m.\u001b[39msum()  \u001b[38;5;66;03m# Count of true negatives\u001b[39;00m\n\u001b[1;32m    236\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtotal_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtp_count \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtn_count \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfp_count \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfn_count\n\u001b[0;32m--> 238\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtransform\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39m, reduce_dims\u001b[38;5;241m=\u001b[39m\u001b[43mreduce_dims\u001b[49m, preserve_dims\u001b[38;5;241m=\u001b[39mpreserve_dims):\n\u001b[1;32m    239\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[1;32m    240\u001b[0m \u001b[38;5;124;03m    '''\u001b[39;00m\n\u001b[1;32m    241\u001b[0m     cd \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgenerate_counts(reduce_dims, preserve_dims)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'reduce_dims' is not defined"
     ]
    }
   ],
   "source": [
    "import scores.categorical\n",
    "import xarray as xr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2e5214b-fb6a-4e04-b208-0857e98d1beb",
   "metadata": {},
   "source": [
    "# Overview of Contingency Scores\n",
    "\n",
    "Many people will be familiar with the following term: accuracy, true positives, false negatives, true positive rate. These terms all apply to a contingency table. Producing these scores is inherently a three-step process. These three steps may be drawn out individually, or performed in one function call in a combined way. The steps are as follows:\n",
    "\n",
    "1. If needed, use an \"event definition\" to convert forecast values to forecasts of events or non-events, aka event tables.\n",
    "2. Produce the contingency table, which holds true positives, true negativates, false positives and false negatives.\n",
    "3. Calculate the scores as needed from the contingency table\n",
    "\n",
    "`scores` provides support for all three steps, plus convenient functions for working efficiently. Most of the scores APIs are functional in nature, however introducing some classes will make contingency scores much easier to calculate and work with, particularly for establishing response curves to different thresholds or more complex use cases. This notebook starts with simple examples and build up to plotting the response curve of two n-dimensional inputs to a varying event threshold."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e0c9a36-55bb-4e5c-b605-fa5b2656b0de",
   "metadata": {},
   "source": [
    "## Making Event Tables\n",
    "\n",
    "Some forecasts systems produce forecasts of \"events\". An event might be for example \"it will rain\", or \"a tropical cyclone will occur\". These overlay a human layer on the physical phenomena involved, and the event either happens or it doesn't. \n",
    "\n",
    "Typically, forecast systems (including NWP or point forecasts) will generate numerical data rather than categorical data. So, the first step of deriving a contingency score is often to generate the event/non-event tables for the forecast and observed conditions. Sometimes, the user will have their own way of doing things, and so `scores` will accept such event tables as input.\n",
    "\n",
    "However, sometimes users will want a streamlined way of defining events, and then using scores to generate the event tables and contingency tables together. This notebook demonstrates several approaches, starting with sample real-varying data and deriving the contingency scores.\n",
    "\n",
    "Consider to begin with the following two tables of forecast values. The values are plausible for either temperatures or precipitation rates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fdad07a-0395-4490-a435-1f7507816fd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Provides a basic forecast data structure in three dimensions\n",
    "simple_forecast = xr.DataArray(\n",
    "    [\n",
    "\t\t[\n",
    "\t\t\t[0.9, 0.0,   5], \n",
    "\t\t\t[0.7, 1.4, 2.8],\n",
    "\t\t\t[.4,  0.5, 2.3],\n",
    "\t\t], \n",
    "\t\t\t[\n",
    "\t\t\t[1.9, 1.0,  1.5], \n",
    "\t\t\t[1.7, 2.4,  1.1],\n",
    "\t\t\t[1.4,  1.5, 3.3],\n",
    "\t\t], \n",
    "\t],\n",
    "\tcoords=[[10, 20], [0, 1, 2], [5, 6, 7]], dims=[\"height\", \"lat\", \"lon\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6661e3fe-1f01-4fcd-a7ec-353a1a8e3a04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Within 0.1 or 0.2 of the forecast in all cases except one\n",
    "# Can be used to find some exact matches, and some close matches\n",
    "simple_obs = xr.DataArray(\n",
    "    [\n",
    "\t\t[\n",
    "\t\t\t[0.9, 0.0,   5], \n",
    "\t\t\t[0.7, 1.3, 2.7],\n",
    "\t\t\t[.3,  0.4, 2.2],\n",
    "\t\t], \n",
    "\t\t\t[\n",
    "\t\t\t[1.7, 1.2,  1.7], \n",
    "\t\t\t[1.7, 2.2,  3.9],\n",
    "\t\t\t[1.6,  1.2, 9.9],\n",
    "\t\t], \n",
    "\t],\n",
    "\tcoords=[[10, 20], [0, 1, 2], [5, 6, 7]], dims=[\"height\", \"lat\", \"lon\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3b9a4ad-3a63-45ee-90f6-bf2087aa18cf",
   "metadata": {},
   "source": [
    "The first step of the three-step process is to create event tables for the forecast and observed data. In this case, we will determine an event to have occurred if the value is greater than 1.3. Some users will want to perform this calculation themselves (or may be working with a supplied data set where this has been done already. Others may wish to utilise the classes within scores for reasons of efficiency or re-used. `scores` provides a general class called an \"EventOperator\". Users can implement this interface themselves for complex scores (we will see an example of this much later), or use one of the in-built operator types. In this case, we will use a simple ThresholdOperator. This can be configured to any of the standard Python operators (e.g. greater-than, less-than or many others). The following code creates a simple \"greater\" than operator which by default creates events with a threshold of \"> 1.3\". It can be repeatedly called with different event thresholds, for reasons that will be explained later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70a9fd8d-af7b-472a-a6ab-7355a510a6b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# An event here is defined as a value (e.g. temperature) above 1.3\n",
    "# The EventThresholdOperator can take a variety of operators from the python \"operator\" module, or a user-defined function\n",
    "# The default is operator.gt, which is the same as \">\" but in functional form.\n",
    "event_operator = scores.categorical.ThresholdEventOperator(default_event_threshold=1.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3447d68f-c7cb-40af-bdb0-42c5f88f4c43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some users will want to visualise or utilise the event tables directly. This is not necessarily going to be typical, but is demonstrated here for those who wish to step through the process.\n",
    "forecast_events, observed_events = event_operator.make_event_tables(simple_forecast, simple_obs)\n",
    "print(forecast_events)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dec28e21-6d2c-486c-8387-b6d164dce570",
   "metadata": {},
   "source": [
    "## Making Contingency Tables\n",
    "\n",
    "Once the event tables have been made, the next step is to make the contingency table. It is possibly more common to make the contingency tables from the event operator directly, but we will show it first as separate steps, and then show how to do the two things at once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cab2d73-ca4b-4c90-b0e2-db940c0cd198",
   "metadata": {},
   "outputs": [],
   "source": [
    "contingency_table = scores.categorical.BinaryContingencyTable(forecast_events, observed_events)\n",
    "contingency_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17f971df-7d39-4ddd-9a9b-98b88e9a71dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# It is also possible, and briefer, to make the binary contingency table directly from the event operator, as follows:\n",
    "contingency_table = event_operator.make_table(simple_forecast, simple_obs)\n",
    "contingency_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3814d56b-d283-4bb4-a582-e030623b8827",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Further, if it turn out you want them, the tables are still there \n",
    "contingency_table.forecast_events"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fdf96b0-2439-4d01-9fac-39397c4de55a",
   "metadata": {},
   "source": [
    "## Calculating Contingency Scores\n",
    "\n",
    "The table can then be utilised to calculate a wide variety of scores which are based on this table. \n",
    "\n",
    "This is probably also the time for a slight diversion on \"why\" this is the way to do things. Xarray, for all its sophistication, also has some limitations. Once of those limitations is the ability to make something called a \"Subclass\". Ideally, the contingency table would \"be\" an `xarray` object itself. Unfortunately, for reasons which are too long to cover here, that is not straightforward to do reliably."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f69c5863-57f9-4b85-a3bd-c2d81163d63a",
   "metadata": {},
   "outputs": [],
   "source": [
    "contingency_table.accuracy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b2ae506-5e5f-4934-bb7f-509ca955b36c",
   "metadata": {},
   "outputs": [],
   "source": [
    "contingency_table.false_alarm_rate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5c6e068-d671-486b-b383-e2e2fe2bcf8e",
   "metadata": {},
   "source": [
    "# More Complex Use Cases\n",
    "\n",
    "These examples are all straightforward in terms of the flexibility and power of the API to explore complexity in the underlying data. The data above includes a three-dimensional structure, indexed by height, latitude and longitude. It may be of interest to understand how accuracy might vary by height, for example. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6da1026-9e82-4dd5-ba7e-f66b14d31ed4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If it is wanted, the underlying event counts can be accessed\n",
    "new_table = contingency_table.transform(preserve_dims='height')\n",
    "new_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db8853b9-517a-4e39-ae52-e0b901877df6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
